{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API v2 to MongoDB\n",
    "\n",
    "Functions for storing tweets and Twitter user data in MongoDB. Includes a function to gather historical data from a list of categorized accounts provided by the user in an Excel spreadsheet.\n",
    "\n",
    "To do:\n",
    "* Implement a function to gather only new tweets from a user or search;\n",
    "* Fail elegantly in case of a typo or deleted account in the user-provided spreadsheet;\n",
    "* Fail elegantly and enable a smooth restart in case of API errors;\n",
    "* Implement logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pymongo\n",
    "import searchtweets\n",
    "from twitter_api import recent_search, user_lookup, user_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env BEARER_TOKEN= [Your Token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_database():\n",
    "    \"\"\"Create indices for the MongoDB collections\"\"\"\n",
    "    requested_accounts.create_index('user_id', unique = True)\n",
    "    twitter_user_data.create_index('id', unique = True)\n",
    "    collected_tweets.create_index('id', unique = True)\n",
    "    collected_tweets.create_index([('text', 'text')], name = \"tweet_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_excel_2(input_file):\n",
    "    \"\"\"Reads Excel file and returns username and category as list of tuples\"\"\"\n",
    "    input_data = pd.read_excel(input_file)\n",
    "    excel_data = input_data.to_records(index=False)\n",
    "    print(excel_data)\n",
    "    return(excel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve list of user_ids, categories that have loaded = 0\n",
    "def list_new_accounts():\n",
    "    \"\"\"Checks number of accounts in the database that do not have associated Twitter user IDs. \n",
    "    Returns a dictionary in the format {category1:[account1, account2], category2:[account3, account4]}\"\"\"\n",
    "    \n",
    "    # Report number of accounts with loaded == 0\n",
    "    num_to_load = db.requested_accounts.count_documents({\"loaded\":0})\n",
    "    print(f\"Number of usernames to lookup: {num_to_load}\")\n",
    "\n",
    "    # Retrieve list of categories currently in the username database\n",
    "    categories_in_use = db.requested_accounts.distinct('category')\n",
    "    print(f\"Categories in database: {categories_in_use}\")\n",
    "\n",
    "    # Create lists of unretrieved account by category\n",
    "    account_lists = {}\n",
    "    for item in categories_in_use:\n",
    "        accounts =[]\n",
    "        for entry in db.requested_accounts.find({\"category\":item, \"loaded\":0}):\n",
    "            accounts.append(entry['user_id'])\n",
    "        account_lists[item] = accounts\n",
    "\n",
    "    print(account_lists)\n",
    "    return(account_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert userdata returned by Twitter into MongoDB\n",
    "def load_userdata(userdata, cat):\n",
    "    new_userdata = json.loads(userdata)\n",
    "    for entry in new_userdata['data']:\n",
    "        try:\n",
    "            entry['date_added'] = time.strftime(\"%Y/%m/%d\")\n",
    "            entry['time_added'] = time.strftime(\"%H:%M%:%S_%Y/%m/%d\")\n",
    "            entry['category'] = cat\n",
    "            entry['hist_data_collected'] = 0\n",
    "            twitter_user_data.insert_one(entry)\n",
    "            \n",
    "            # Write existing database to indicate userdata has been read\n",
    "            username = entry['username']\n",
    "            db.requested_accounts.update_one({\"user_id\":username},{'$set':{\"loaded\":1}})\n",
    "            \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a user's historical tweets\n",
    "def get_historical(user_id, username, cat, **kwargs):\n",
    "    \"\"\"Get tweets since Dec 4 for user_id and enter into MongodB\"\"\"\n",
    "    print(f\"Gathering up to 100 tweets for user {username}\")\n",
    "    if 'next_token' in kwargs:\n",
    "        some_tweets = user_tweets.main(user_id, next_token = kwargs.get('next_token'))\n",
    "    else:\n",
    "        some_tweets = user_tweets.main(user_id)\n",
    "        \n",
    "    jsonified_tweets = json.loads(some_tweets)\n",
    "    \n",
    "    # If the user has tweeted in the time period specified, collect the tweets\n",
    "    if 'data' in jsonified_tweets:\n",
    "        for tweet in jsonified_tweets['data']:\n",
    "            try:\n",
    "                tweet['username'] = username\n",
    "                tweet['category'] = cat\n",
    "                collected_tweets.insert_one(tweet)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # If there are more tweets to collect from the user, get the next batch\n",
    "    if 'next_token' in jsonified_tweets['meta']:\n",
    "        next_token = jsonified_tweets['meta']['next_token']\n",
    "        time.sleep(2)\n",
    "        get_historical(user_id, username, cat, next_token = next_token)\n",
    "    else:\n",
    "        # If finished, record that historical data has been collected for this user\n",
    "        db.twitter_user_data.update_one({\"id\":user_id},{'$set':{\"hist_data_collected\":1}})\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load list of user_ids and categories into MongoDB\n",
    "def load_excel_to_mongo():\n",
    "    \"\"\"Takes account_list.xlsx, adds new accounts into requested_accounts collection\"\"\"\n",
    "    excel_data = parse_excel_2('account_list.xlsx')\n",
    "\n",
    "    requested_accounts = db['requested_accounts']\n",
    "\n",
    "    for item in excel_data:\n",
    "        try:\n",
    "            entry = {}\n",
    "            user, category = item\n",
    "            entry['user_id'] = user\n",
    "            entry['category'] = category\n",
    "            entry['loaded'] = 0 # has userdata been collected yet?\n",
    "            requested_accounts.insert_one(entry)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new tweets\n",
    "def get_new_tweets():\n",
    "    \"\"\"Gather new tweets for user since last tweet in DB\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database\n",
    "client = pymongo.MongoClient()\n",
    "db = client['GA_Runoffs']\n",
    "\n",
    "# Create test userdata collection\n",
    "requested_accounts = db['requested_accounts']\n",
    "twitter_user_data = db['twitter_user_data']\n",
    "collected_tweets = db['collected_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_excel_to_mongo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take accounts from list_new_accounts, query Twitter API for user info, enter into MongoDB\n",
    "# TODO: Fail elegantly if typo in account list (bad request reutrns error 400)\n",
    "\n",
    "account_lists = list_new_accounts()\n",
    "\n",
    "for cat in list(account_lists.keys()):\n",
    "    usernames = account_lists[cat]\n",
    "    if len(usernames) >= 1:\n",
    "        users = ','.join(usernames)\n",
    "        users = 'usernames='+users\n",
    "        print(f\"User query string: {users}\")\n",
    "\n",
    "        userdata = user_lookup.main(users)\n",
    "\n",
    "        load_userdata(userdata, cat)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Twitter IDs, usernames, and categories of any users for whom historical data has not been collected\n",
    "to_collect = db.twitter_user_data.find({'hist_data_collected':0})\n",
    "to_collect_list = []\n",
    "\n",
    "for item in to_collect:\n",
    "    userid = item['id']\n",
    "    username = item['username']\n",
    "    category = item['category']\n",
    "    data = [userid, username, category]\n",
    "    to_collect_list.append(data)\n",
    "    \n",
    "print(to_collect_list)\n",
    "\n",
    "# Get data of uncollected users\n",
    "for item in to_collect_list:\n",
    "    get_historical(item[0], item[1], item[2])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return tweets by search query\n",
    "def search_recent_tweets(query: str, category: str, counter: int, **kwargs):\n",
    "    \"\"\"Query recent tweets and add to MongoDB with a category label\"\"\"\n",
    "    if counter >=10000:\n",
    "        print(\"Gathered maximum number of tweets\")\n",
    "        return 0\n",
    "    \n",
    "    else: \n",
    "        print(f\"Gathering up to 10,000 tweets for query {query}. Approx {counter} collected so far\")\n",
    "\n",
    "        if 'next_token' in kwargs:\n",
    "            some_tweets = recent_search.main(query, next_token = kwargs.get('next_token'))\n",
    "            counter += 100\n",
    "        else:\n",
    "            some_tweets = recent_search.main(query)\n",
    "            counter += 100\n",
    "\n",
    "        jsonified_tweets = json.loads(some_tweets)\n",
    "\n",
    "        # If the search returned results, collect the tweets\n",
    "        if 'data' in jsonified_tweets:\n",
    "            for tweet in jsonified_tweets['data']:\n",
    "                try:\n",
    "                    tweet['query'] = query\n",
    "                    tweet['category'] = category\n",
    "                    collected_tweets.insert_one(tweet)\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # If there are more tweets to collect from the user, get the next batch\n",
    "        if 'next_token' in jsonified_tweets['meta']:\n",
    "            next_token = jsonified_tweets['meta']['next_token']\n",
    "            time.sleep(2)\n",
    "            search_recent_tweets(query, category, counter, next_token = next_token)\n",
    "        else:\n",
    "            print(f\"Completed query {query} with approximately {counter} tweets collected.\")\n",
    "            return 0\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Tweets that mention @ReverendWarnock and that are not retweets\n",
    "search_recent_tweets(\"(%40ReverendWarnock) -is:retweet\", \"hashtag_search\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Tweets that mention #HoldTheLine and that are not retweets\n",
    "search_recent_tweets(\"%23holdtheline -is:retweet\", \"holdtheline_ecosystem\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Tweets that use hashtag #DemCastGA and that are not retweets\n",
    "search_recent_tweets(\"%23demcastga -is:retweet\", \"demcast_ecosystem\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search tweets that use hashtags #GAPol or #GASen and that are not rewtweets\n",
    "search_recent_tweets(\"(%23gapol OR %23gasen) -is:retweet\", \"hashtag_search\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show categories currently in the collected_tweets collection\n",
    "db.collected_tweets.distinct(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ID of most recent tweet for a query\n",
    "def get_most_recent_entry(query):\n",
    "    most_recent = db.collected_tweets.find(query).sort(\"id\",pymongo.DESCENDING).limit(1)\n",
    "    most_recent_df = pd.DataFrame(list(most_recent))\n",
    "    return(most_recent_df.iloc[0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Twitter ID of most recent Tweet collected for category hashtag_search\n",
    "get_most_recent_entry({\"category\":{\"$eq\":\"hashtag_search\"}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
